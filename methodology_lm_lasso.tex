\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amssymb}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{hyperref}

\title{Methodology: Cherry Blossom Bloom-Date Prediction \\ Linear Model and LASSO}
\author{Peak Bloom Prediction Workflow}
\date{\today}

\begin{document}
\maketitle

\section{Objective}
This document summarizes the modeling methodology used to predict annual cherry blossom peak bloom timing (day-of-year) for each location, with a focus on the standard \textbf{linear model (LM)} and a secondary \textbf{LASSO} model.

\section{Data Sources and Initialization}
The workflow loads and harmonizes:
\begin{itemize}[leftmargin=*]
    \item Bloom history data by location and year (peak bloom date and day-of-year).
    \item Daily climate station data (temperature, precipitation, station metadata).
\end{itemize}

Key preprocessing decisions include:
\begin{itemize}[leftmargin=*]
    \item Restrict records to years $\geq 1973$.
    \item Map NOAA stations to bloom locations.
    \item Keep selected climate variables (temperature and precipitation inputs for the standard model pipeline).
    \item Fill only short internal temperature gaps (less than 3 consecutive days) by linear interpolation.
\end{itemize}

\section{Feature Engineering for Standard Model}
From daily climate records and bloom events, yearly pre-bloom predictors are constructed.

\subsection{Altitude/Location Adjustment}
For each location, station-to-bloom-site altitude difference is computed using:
\begin{itemize}[leftmargin=*]
    \item Station altitude from climate station elevation.
    \item Bloom-site altitude from bloom history metadata.
\end{itemize}

\paragraph{Why altitude correction is needed.}
The daily climate observations come from meteorological stations that are not always colocated with the bloom observation sites.
Because near-surface air temperature typically decreases with elevation, directly using station temperatures can introduce a systematic bias in pre-bloom thermal features when station altitude and bloom-site altitude differ.
Without correction, the model may learn location-specific offsets that are artifacts of station placement rather than biological response.

\paragraph{Physical basis.}
We use a standard environmental lapse-rate approximation to translate station temperatures to bloom-site-equivalent temperatures.
A lapse-rate temperature correction is applied:
\begin{equation}
\Delta T = \gamma \cdot \frac{h_{\text{station}} - h_{\text{bloom}}}{1000}, \quad \gamma = 6.5\,^{\circ}\text{C}/\text{km}.
\end{equation}
Adjusted daily temperatures are:
\begin{equation}
T^{\text{adj}}_{\max} = T_{\max} + \Delta T, \qquad
T^{\text{adj}}_{\min} = T_{\min} + \Delta T.
\end{equation}

Interpretation of sign:
\begin{itemize}[leftmargin=*]
    \item If $h_{\text{station}} > h_{\text{bloom}}$, then $\Delta T > 0$ and temperatures are adjusted upward.
    \item If $h_{\text{station}} < h_{\text{bloom}}$, then $\Delta T < 0$ and temperatures are adjusted downward.
\end{itemize}

\paragraph{Implementation details in this workflow.}
\begin{itemize}[leftmargin=*]
    \item A representative station altitude is estimated per location from station metadata.
    \item A representative bloom-site altitude is estimated per location from bloom metadata.
    \item The altitude correction is applied at daily resolution before pre-bloom aggregation.
    \item Corrected temperature features are then used in both LM and LASSO pipelines.
\end{itemize}

\paragraph{Assumptions and limitations.}
\begin{itemize}[leftmargin=*]
    \item The lapse rate is treated as constant in space and time.
    \item Microclimate effects (urban heat island, slope/aspect, canopy, local cold-air pooling) are not explicitly modeled.
    \item A fixed linear correction may under- or over-correct in some regions/seasons.
\end{itemize}
Despite these limitations, altitude correction reduces first-order station-to-site temperature bias and improves comparability of thermal predictors across locations.

\subsection{Pre-bloom Annual Aggregates}
For each location-year, using all days from Jan 1 through bloom date:
\begin{itemize}[leftmargin=*]
    \item $\text{mean\_tmax\_adj\_prebloom}$
    \item $\text{total\_prcp\_prebloom}$
\end{itemize}
The target is bloom day-of-year, $y = \text{bloom\_doy}$.

\section{Train / Validation / Test Design}
The standard model uses location-based domain split:
\begin{itemize}[leftmargin=*]
    \item \textbf{Training locations}: Kyoto, Washington DC, Liestal.
    \item \textbf{Holdout locations}: all remaining locations.
\end{itemize}

For holdout locations, years are ordered chronologically and split into:
\begin{itemize}[leftmargin=*]
    \item first half $\rightarrow$ validation,
    \item second half $\rightarrow$ test.
\end{itemize}

This tests geographic transferability while preserving temporal order within each holdout location.

\section{Primary Model: Linear Regression (LM)}
The baseline model is:
\begin{equation}
\text{bloom\_doy} = \beta_0 +
\beta_1\,\text{mean\_tmax\_adj\_prebloom} +
\beta_2\,\text{total\_prcp\_prebloom} + \varepsilon.
\end{equation}

Evaluation metrics on validation/test:
\begin{equation}
\text{MAE} = \frac{1}{n}\sum_{i=1}^{n} |\hat y_i - y_i|,
\qquad
\text{RMSE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(\hat y_i - y_i)^2}.
\end{equation}

\section{Secondary Model: LASSO}
A LASSO regression is fit using the same predictors and target, with $\lambda$ selected by cross-validation on training data only.

Optimization objective:
\begin{equation}
\min_{\beta_0,\beta} \left\{
\frac{1}{2n}\sum_{i=1}^{n}(y_i - \beta_0 - x_i^\top\beta)^2 + \lambda\sum_{j=1}^{p}|\beta_j|
\right\}.
\end{equation}

The selected model uses $\lambda_{\min}$ from CV and is scored on validation/test using the same MAE and RMSE metrics as LM.

\section{2026 Forecasting and Uncertainty}
\subsection{Feature Construction for 2026}
For each location, the most recent available feature row is used as the predictor baseline and assigned year $=2026$.

\subsection{LM 90\% Confidence Bounds}
For the linear model, 90\% confidence intervals are produced directly from the regression prediction interval output for the mean response:
\begin{itemize}[leftmargin=*]
    \item predicted DOY,
    \item lower/upper 90\% DOY bounds,
    \item converted calendar-date bounds,
    \item uncertainty width as $\pm$ days.
\end{itemize}

\subsection{LASSO 90\% Confidence Bounds}
Because standard closed-form confidence bounds are not directly provided for penalized fits, uncertainty is estimated via bootstrap on training rows:
\begin{enumerate}[leftmargin=*]
    \item Resample training rows with replacement.
    \item Refit LASSO at fixed $\lambda_{\min}$.
    \item Predict 2026 DOY for each location.
    \item Repeat (e.g., 500 replicates) and take empirical 5th/95th percentiles for a 90\% interval.
\end{enumerate}
The reported outputs include lower/upper bounds and $\pm$ day summaries.

\paragraph{Why bootstrap is used here.}
For ordinary least squares, uncertainty can be derived analytically under standard assumptions.
For LASSO, coefficient shrinkage and variable selection make classical interval formulas less direct and often unstable for small-sample, correlated predictors.
Bootstrap prediction intervals provide a practical, model-consistent way to quantify forecast uncertainty without relying on closed-form post-selection inference.

\paragraph{Bootstrap algorithm used in this workflow.}
Let $\hat\lambda = \lambda_{\min}$ from cross-validation on the training split.
For each bootstrap replicate $b = 1, \dots, B$ (with $B=500$):
\begin{enumerate}[leftmargin=*]
    \item Draw a bootstrap sample of training rows (same size as training set, sampled with replacement).
    \item Fit a LASSO model on the bootstrap sample using \emph{fixed} penalty $\hat\lambda$.
    \item Predict 2026 bloom DOY for each location, obtaining $\hat y^{(b)}_{\ell,2026}$.
\end{enumerate}
After collecting $\{\hat y^{(1)}_{\ell,2026},\dots,\hat y^{(B)}_{\ell,2026}\}$ for each location $\ell$:
\begin{equation}
\text{CI}_{90\%,\ell} = \left[q_{0.05}\left(\hat y^{(b)}_{\ell,2026}\right),\; q_{0.95}\left(\hat y^{(b)}_{\ell,2026}\right)\right].
\end{equation}
The reported uncertainty is then summarized as:
\begin{equation}
\pm\text{Days}_{\ell} = \frac{\text{Upper}_{\ell}-\text{Lower}_{\ell}}{2}.
\end{equation}

\paragraph{Why $\lambda$ is fixed during bootstrap.}
Keeping $\lambda$ fixed at $\lambda_{\min}$ isolates sampling variability in the training rows while preserving the selected model complexity used for final deployment.
Re-tuning $\lambda$ inside each bootstrap replicate is possible, but can mix hyperparameter-selection variability with coefficient-estimation variability and add substantial computational cost.

\paragraph{Interpretation.}
The resulting 90\% intervals are empirical prediction-uncertainty bands for the LASSO forecast under the observed training distribution and model specification.
They should be interpreted as approximate uncertainty summaries (not exact finite-sample guarantees), especially in the presence of nonstationarity, covariate shift, or structural climate trend changes.

\section{Model Comparison Outputs}
The process stores:
\begin{itemize}[leftmargin=*]
    \item Validation/test metrics by model (LM vs LASSO).
    \item Prediction-level residual tables by split and model.
    \item 2026 prediction tables for LM and LASSO.
    \item A side-by-side 2026 comparison including DOY difference
    $(\text{LASSO} - \text{LM})$.
\end{itemize}

\section{Outputs for Final Report}
This section can be used directly in the final competition report to summarize model performance and 2026 predictions.

\subsection{Validation/Test Model Metrics}
The following values are taken from \texttt{data/model\_outputs/model\_metrics.csv}.

\begin{table}[h!]
\centering
\small
\begin{tabular}{lccc}
\toprule
Model & Split & MAE (days) & RMSE (days) \\
\midrule
Linear & Validation ($n=24$) & 6.62 & 8.06 \\
Linear & Test ($n=15$) & 7.59 & 9.45 \\
LASSO & Validation ($n=24$) & 6.62 & 8.05 \\
LASSO & Test ($n=15$) & 7.59 & 9.45 \\
\bottomrule
\end{tabular}
\caption{Out-of-location validation/test performance summary for LM and LASSO.}
\label{tab:model_metrics}
\end{table}

\subsection{Parameter Estimates (90\% CI)}
The following values are taken from
\texttt{data/model\_outputs/model\_parameter\_estimates\_90ci\_comparison.csv}.

\begin{table}[h!]
\centering
\small
\begin{tabular}{lccc}
\toprule
Model & Term & Estimate & 90\% CI \\
\midrule
LM & Intercept & 106.54 & [100.40, 112.78] \\
LM & mean\_tmax\_adj\_prebloom & -1.87 & [-2.48, -1.26] \\
LM & total\_prcp\_prebloom & 0.031 & [0.017, 0.045] \\
LASSO & Intercept & 106.54 & [100.45, 113.22] \\
LASSO & mean\_tmax\_adj\_prebloom & -1.86 & [-2.53, -1.23] \\
LASSO & total\_prcp\_prebloom & 0.031 & [0.015, 0.047] \\
\bottomrule
\end{tabular}
\caption{Parameter estimates and 90\% confidence intervals for the reduced-feature LM and LASSO models.}
\label{tab:param_estimates}
\end{table}

\subsection{2026 Prediction Results (LM vs LASSO)}
The following values are taken from:
\begin{itemize}[leftmargin=*]
    \item \texttt{data/model\_outputs/predictions\_2026\_linear.csv}
    \item \texttt{data/model\_outputs/predictions\_2026\_lasso.csv}
    \item \texttt{data/model\_outputs/predictions\_2026\_comparison.csv}
\end{itemize}

\begin{table}[h!]
\centering
\small
\begin{tabular}{lcccc}
\toprule
Location & LM Date & LM $\pm$ Days & LASSO Date & LASSO $\pm$ Days \\
\midrule
Kyoto & 2026-03-29 & 3.65 & 2026-03-29 & 3.00 \\
Washington DC & 2026-04-02 & 1.80 & 2026-04-02 & 1.57 \\
Liestal & 2026-04-04 & 1.29 & 2026-04-04 & 1.58 \\
Vancouver & 2026-04-10 & 1.83 & 2026-04-10 & 1.99 \\
New York City & 2026-04-09 & 2.15 & 2026-04-09 & 1.78 \\
\bottomrule
\end{tabular}
\caption{Predicted 2026 peak bloom dates with uncertainty summarized as $\pm$ days.}
\label{tab:pred2026_lm_lasso}
\end{table}

\subsection{Model Difference (LASSO - LM)}
\begin{table}[h!]
\centering
\small
\begin{tabular}{lc}
\toprule
Location & DOY Difference (LASSO - LM) \\
\midrule
Kyoto & +0.05 \\
Washington DC & +0.02 \\
Liestal & +0.01 \\
Vancouver & -0.03 \\
New York City & -0.02 \\
\bottomrule
\end{tabular}
\caption{Difference in predicted bloom day-of-year between LASSO and linear models for 2026.}
\label{tab:pred2026_diff}
\end{table}

\section{Reproducibility Notes}
\begin{itemize}[leftmargin=*]
    \item A fixed random seed is used for splitting and bootstrap reproducibility.
    \item All intermediate and final objects are saved as RData artifacts.
    \item Modeling scripts are modularized into data prep, feature construction, and model fitting stages.
\end{itemize}

\end{document}
